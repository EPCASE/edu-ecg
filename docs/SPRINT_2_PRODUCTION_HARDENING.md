# üöÄ SPRINT 2 - PRODUCTION HARDENING

**Date d√©but :** 2026-01-10  
**Date fin :** 2026-01-24 (2 semaines)  
**Objectif :** Transformer le POC en MVP Production-Ready  
**Lead :** Amelia (Dev) + Winston (Architecture)

---

## üéØ OBJECTIFS SPRINT

### Vision
Passer d'un POC fonctionnel √† un syst√®me production-ready capable de servir 100+ √©tudiants avec fiabilit√©, performance et observabilit√©.

### Success Metrics
- ‚úÖ Cache LLM : R√©duction 70% appels API
- ‚úÖ Latence : <2s par correction (actuellement ~3-5s)
- ‚úÖ Disponibilit√© : 99.5% uptime
- ‚úÖ Co√ªt : <$0.01 par correction (actuellement ~$0.05)
- ‚úÖ Tests : Coverage >80%
- ‚úÖ Monitoring : Dashboard Grafana op√©rationnel

---

## üìÖ PLANNING D√âTAILL√â

### üóìÔ∏è SEMAINE 1 : Infrastructure & Performance

#### **Jour 1-2 (Lundi-Mardi) : Cache LLM Redis** üî•

**Ticket #1 : Impl√©mentation Cache Redis**

**Objectif :** R√©duire appels API OpenAI de 70% via cache intelligent

**Tasks :**
1. Setup Redis (local + Heroku addon)
2. Cr√©er `backend/services/llm_cache_service.py`
3. Int√©grer dans `llm_semantic_matcher.py`
4. Tests unitaires cache (hit/miss/expiration)

**Spec technique :**
```python
# Cache key format
key = f"llm_match:{hash(student_concept)}:{hash(expected_concept)}"

# Cache structure
{
    "match": true,
    "match_type": "abbreviation",
    "confidence": 95,
    "explanation": "...",
    "cached_at": "2026-01-10T10:30:00Z",
    "ttl": 86400  # 24h
}
```

**Acceptance Criteria :**
- [ ] Redis connect√© (local + prod)
- [ ] Cache hit rate >60% apr√®s 1h utilisation
- [ ] Fallback gracieux si Redis down
- [ ] TTL configurable (env var)
- [ ] Tests unitaires passent

**Estimation :** 12h  
**Priorit√© :** P0 (Critique)

---

#### **Jour 3 (Mercredi) : Rate Limiting & Retry Logic** ‚ö°

**Ticket #2 : Rate Limiting OpenAI API**

**Objectif :** √âviter d√©passement quota OpenAI (60 req/min tier 1)

**Tasks :**
1. Impl√©menter `RateLimiter` class (token bucket algorithm)
2. Queue syst√®me si d√©passement
3. Backoff exponentiel sur erreurs
4. Tests stress (100 req simultan√©es)

**Spec technique :**
```python
class RateLimiter:
    def __init__(self, max_requests=60, time_window=60):
        self.max_requests = max_requests
        self.time_window = time_window
        self.requests = deque()
    
    def acquire(self):
        # Wait if needed, return when allowed
        pass
```

**Acceptance Criteria :**
- [ ] Max 60 req/min respect√©
- [ ] Queue FIFO si d√©passement
- [ ] Timeout configurable
- [ ] Metrics expos√©es (requests_queued, requests_throttled)

**Estimation :** 6h  
**Priorit√© :** P0 (Critique)

---

**Ticket #3 : Retry Logic avec Backoff**

**Objectif :** Resilience face aux timeouts/erreurs API

**Tasks :**
1. Decorator `@retry_with_backoff`
2. 3 tentatives : 5s ‚Üí 10s ‚Üí 15s
3. Fallback matching d√©terministe si 3 √©checs
4. Logging d√©taill√© erreurs

**Spec technique :**
```python
@retry_with_backoff(max_retries=3, backoff_factor=2)
def semantic_match(student_concept, expected_concept):
    # ... existing code
    pass
```

**Acceptance Criteria :**
- [ ] 3 tentatives avec backoff exponentiel
- [ ] Fallback d√©terministe apr√®s 3 √©checs
- [ ] Logs structur√©s (JSON)
- [ ] Tests mock API failures

**Estimation :** 4h  
**Priorit√© :** P1 (Important)

---

#### **Jour 4 (Jeudi) : Logging Structur√©** üìù

**Ticket #4 : Migration vers Logging Structur√©**

**Objectif :** Logs JSON pour ELK stack (Elasticsearch, Logstash, Kibana)

**Tasks :**
1. Remplacer `print()` par `logger.info()`
2. Format JSON structur√©
3. Contexte enrichi (user_id, case_id, session_id)
4. Niveaux : DEBUG, INFO, WARN, ERROR

**Spec technique :**
```json
{
  "timestamp": "2026-01-10T10:30:45.123Z",
  "level": "INFO",
  "service": "llm_semantic_matcher",
  "event": "match_found",
  "context": {
    "user_id": "greg_001",
    "case_id": "EPIC1_002",
    "session_id": "sess_abc123"
  },
  "data": {
    "student_concept": "BAV2M1",
    "expected_concept": "BAV 2 Mobitz 1",
    "match_type": "abbreviation",
    "confidence": 95,
    "cached": true,
    "latency_ms": 45
  }
}
```

**Acceptance Criteria :**
- [ ] Tous `print()` remplac√©s
- [ ] Format JSON valide
- [ ] Rotation logs (max 100MB)
- [ ] Pas de PII (donn√©es personnelles) dans logs

**Estimation :** 4h  
**Priorit√© :** P1 (Important)

---

#### **Jour 5 (Vendredi) : Configuration Flexible** ‚öôÔ∏è

**Ticket #5 : Externaliser Configuration**

**Objectif :** Param√®tres modifiables sans red√©ploiement

**Tasks :**
1. Cr√©er `config/llm_config.yaml`
2. Variables d'environnement (.env)
3. Validation sch√©ma (pydantic)
4. Hot reload configuration

**Configuration expos√©e :**
```yaml
llm:
  model: "gpt-4o"
  temperature: 0.1
  max_tokens: 300
  confidence_threshold: 70
  retry_max_attempts: 3
  retry_backoff_factor: 2

cache:
  enabled: true
  ttl_seconds: 86400
  redis_url: "redis://localhost:6379"

rate_limit:
  max_requests: 60
  time_window: 60
```

**Acceptance Criteria :**
- [ ] Config YAML charg√©e au d√©marrage
- [ ] Override via env vars (12-factor app)
- [ ] Validation sch√©ma (erreur si invalide)
- [ ] Hot reload sans restart (optionnel)

**Estimation :** 4h  
**Priorit√© :** P2 (Nice to have)

---

### üóìÔ∏è SEMAINE 2 : Observabilit√© & Tests

#### **Jour 6-7 (Lundi-Mardi) : M√©triques Prometheus** üìä

**Ticket #6 : Instrumentation Prometheus**

**Objectif :** M√©triques temps r√©el pour monitoring

**Tasks :**
1. Setup Prometheus client Python
2. Exposer endpoint `/metrics`
3. D√©finir m√©triques cl√©s
4. Int√©grer dans tous services

**M√©triques expos√©es :**
```python
# Compteurs
llm_calls_total{status="success|error|cached"}
llm_cache_hits_total
llm_cache_misses_total
corrections_total{case_id, user_level}

# Histogrammes
llm_latency_seconds{percentile="50|95|99"}
llm_confidence_score{match_type}
llm_cost_dollars

# Gauges
llm_cost_daily_dollars
llm_cost_monthly_dollars
active_users
```

**Acceptance Criteria :**
- [ ] Endpoint `/metrics` r√©pond format Prometheus
- [ ] Toutes m√©triques cl√©s pr√©sentes
- [ ] Labels pertinents (case_id, match_type)
- [ ] Pas d'impact performance (<1ms overhead)

**Estimation :** 10h  
**Priorit√© :** P0 (Critique)

---

#### **Jour 8 (Mercredi) : Dashboard Grafana** üìà

**Ticket #7 : Dashboard Monitoring**

**Objectif :** Visualisation temps r√©el m√©triques

**Tasks :**
1. Setup Grafana (local + Grafana Cloud)
2. Cr√©er dashboard "LLM Semantic Matcher"
3. Panels : latence, co√ªt, cache hit rate, erreurs
4. Alertes (co√ªt >$10/jour, latence >3s)

**Panels dashboard :**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ LLM Semantic Matcher - Production Dashboard    ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                 ‚îÇ
‚îÇ  Latency (p95)          Cache Hit Rate         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ
‚îÇ  ‚îÇ   1.2s      ‚îÇ        ‚îÇ    73%       ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ  ‚ñÉ‚ñÖ‚ñá‚ñÜ‚ñÑ‚ñÉ     ‚îÇ        ‚îÇ  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë  ‚îÇ       ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ
‚îÇ                                                 ‚îÇ
‚îÇ  Daily Cost             Error Rate             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ
‚îÇ  ‚îÇ   $2.45     ‚îÇ        ‚îÇ    0.3%      ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ  ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ     ‚îÇ        ‚îÇ  ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ    ‚îÇ       ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ
‚îÇ                                                 ‚îÇ
‚îÇ  Requests/min           Confidence Avg         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ
‚îÇ  ‚îÇ   24        ‚îÇ        ‚îÇ    88%       ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ  ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ     ‚îÇ        ‚îÇ  ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ      ‚îÇ       ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Alertes configur√©es :**
- üö® Co√ªt > $10/jour ‚Üí Email + Slack
- ‚ö†Ô∏è Latence p95 > 3s ‚Üí Slack
- ‚ö†Ô∏è Error rate > 5% ‚Üí Email + Slack
- ‚ö†Ô∏è Cache hit rate < 50% ‚Üí Slack

**Acceptance Criteria :**
- [ ] Dashboard accessible (Grafana Cloud)
- [ ] 6 panels minimum
- [ ] Alertes configur√©es et test√©es
- [ ] Documentation acc√®s dashboard

**Estimation :** 6h  
**Priorit√© :** P1 (Important)

---

#### **Jour 9 (Jeudi) : Tests Int√©gration** üß™

**Ticket #8 : Suite Tests Compl√®te**

**Objectif :** Coverage >80%, tests automatis√©s

**Tasks :**
1. Tests unitaires (pytest)
2. Tests int√©gration (cache + LLM)
3. Tests E2E (POC flow complet)
4. Mock OpenAI API (vcr.py)

**Structure tests :**
```
tests/
‚îú‚îÄ‚îÄ unit/
‚îÇ   ‚îú‚îÄ‚îÄ test_llm_semantic_matcher.py
‚îÇ   ‚îú‚îÄ‚îÄ test_llm_cache_service.py
‚îÇ   ‚îú‚îÄ‚îÄ test_rate_limiter.py
‚îÇ   ‚îî‚îÄ‚îÄ test_retry_logic.py
‚îú‚îÄ‚îÄ integration/
‚îÇ   ‚îú‚îÄ‚îÄ test_cache_llm_integration.py
‚îÇ   ‚îî‚îÄ‚îÄ test_poc_flow.py
‚îú‚îÄ‚îÄ e2e/
‚îÇ   ‚îî‚îÄ‚îÄ test_correction_complete.py
‚îî‚îÄ‚îÄ fixtures/
    ‚îú‚îÄ‚îÄ mock_openai_responses.yaml
    ‚îî‚îÄ‚îÄ test_cases.json
```

**Coverage targets :**
- llm_semantic_matcher.py : >90%
- llm_cache_service.py : >85%
- correction_llm_poc.py : >70%
- Overall : >80%

**Acceptance Criteria :**
- [ ] Coverage >80%
- [ ] Tous tests passent (green)
- [ ] Tests rapides (<30s suite compl√®te)
- [ ] Mock OpenAI (pas d'appels r√©els)
- [ ] CI/CD int√©gr√© (GitHub Actions)

**Estimation :** 8h  
**Priorit√© :** P0 (Critique)

---

#### **Jour 10 (Vendredi) : CI/CD Pipeline** üîÑ

**Ticket #9 : GitHub Actions Pipeline**

**Objectif :** Automatisation tests + d√©ploiement

**Tasks :**
1. Cr√©er `.github/workflows/ci.yml`
2. Pipeline : lint ‚Üí test ‚Üí build ‚Üí deploy
3. Environnements : dev, staging, prod
4. Secrets management (GitHub Secrets)

**Pipeline structure :**
```yaml
name: CI/CD Pipeline

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

jobs:
  lint:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Lint Python
        run: |
          pip install flake8 black
          flake8 backend/ frontend/
          black --check backend/ frontend/
  
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Run Tests
        run: |
          pip install -r requirements.txt
          pytest --cov=backend --cov-report=xml
      - name: Upload Coverage
        uses: codecov/codecov-action@v3
  
  deploy-staging:
    if: github.ref == 'refs/heads/develop'
    needs: [lint, test]
    runs-on: ubuntu-latest
    steps:
      - name: Deploy to Staging
        run: |
          heroku container:push web --app edu-ecg-staging
          heroku container:release web --app edu-ecg-staging
  
  deploy-prod:
    if: github.ref == 'refs/heads/main'
    needs: [lint, test]
    runs-on: ubuntu-latest
    steps:
      - name: Deploy to Production
        run: |
          heroku container:push web --app edu-ecg-prod
          heroku container:release web --app edu-ecg-prod
```

**Acceptance Criteria :**
- [ ] Pipeline s'ex√©cute sur push/PR
- [ ] Lint + Tests passent
- [ ] Deploy auto staging (branch develop)
- [ ] Deploy auto prod (branch main)
- [ ] Notifications Slack (succ√®s/√©chec)

**Estimation :** 6h  
**Priorit√© :** P1 (Important)

---

## üìä SPRINT BACKLOG R√âSUM√â

| Ticket | Titre | Priorit√© | Estimation | Jour |
|--------|-------|----------|------------|------|
| #1 | Cache LLM Redis | P0 | 12h | 1-2 |
| #2 | Rate Limiting | P0 | 6h | 3 |
| #3 | Retry Logic | P1 | 4h | 3 |
| #4 | Logging Structur√© | P1 | 4h | 4 |
| #5 | Configuration Flexible | P2 | 4h | 5 |
| #6 | M√©triques Prometheus | P0 | 10h | 6-7 |
| #7 | Dashboard Grafana | P1 | 6h | 8 |
| #8 | Tests Int√©gration | P0 | 8h | 9 |
| #9 | CI/CD Pipeline | P1 | 6h | 10 |

**Total effort :** 60h (10 jours √ó 6h/jour)

---

## üéØ DEFINITION OF DONE

### Sprint 2 Termin√© Quand :

**Infrastructure :**
- [x] Redis cache op√©rationnel (hit rate >60%)
- [x] Rate limiting actif (60 req/min)
- [x] Retry logic impl√©ment√© (3 tentatives)
- [x] Logs JSON structur√©s

**Observabilit√© :**
- [x] Prometheus metrics expos√©es
- [x] Dashboard Grafana accessible
- [x] Alertes configur√©es (co√ªt, latence, erreurs)

**Qualit√© :**
- [x] Coverage tests >80%
- [x] CI/CD pipeline op√©rationnel
- [x] Documentation √† jour

**Performance :**
- [x] Latence <2s (p95)
- [x] Co√ªt <$0.01/correction
- [x] Disponibilit√© >99%

---

## üöÄ QUICK WINS (Optionnels)

Si on termine en avance, features bonus :

**Quick Win #1 : Mode Apprentissage/Examen** (4h)
- Toggle UI simple
- Seuil confiance : 70% (apprentissage) vs 85% (examen)
- Badge visuel mode actif

**Quick Win #2 : Health Check Endpoint** (2h)
- `/health` endpoint
- Status : Redis, OpenAI API, DB
- Uptime monitoring

**Quick Win #3 : Admin Dashboard** (6h)
- Streamlit admin interface
- Stats temps r√©el
- Configuration hot-reload
- Flush cache manuel

---

## üìà SUIVI SPRINT

### Daily Standup (9h30 chaque jour)

**Questions :**
1. Qu'est-ce qui a √©t√© fait hier ?
2. Qu'est-ce qui sera fait aujourd'hui ?
3. Y a-t-il des blocages ?

### Sprint Review (Vendredi 24/01 - 14h)

**D√©mo :**
- Cache LLM en action (hit rate dashboard)
- Dashboard Grafana live
- Tests coverage report
- CI/CD pipeline execution

### Sprint Retrospective (Vendredi 24/01 - 15h30)

**Questions :**
1. Qu'est-ce qui a bien fonctionn√© ?
2. Qu'est-ce qui peut √™tre am√©lior√© ?
3. Actions pour Sprint 3

---

## üõ†Ô∏è INFRASTRUCTURE REQUISE

### D√©veloppement Local
```bash
# Redis
docker run -d -p 6379:6379 redis:alpine

# Prometheus
docker run -d -p 9090:9090 prom/prometheus

# Grafana
docker run -d -p 3000:3000 grafana/grafana
```

### Production (Heroku)
```bash
# Addons
heroku addons:create heroku-redis:mini       # $3/mois
heroku addons:create papertrail:choklad      # Gratuit (logs)
heroku addons:create newrelic:wayne          # Gratuit (APM)

# Config
heroku config:set REDIS_URL=redis://...
heroku config:set OPENAI_API_KEY=sk-...
heroku config:set LLM_CACHE_ENABLED=true
```

**Co√ªt mensuel estim√© :** $3 (Redis) + $5 (dyno) = **$8/mois**

---

## üìö DOCUMENTATION

### √Ä Cr√©er
- [ ] `docs/CACHE_ARCHITECTURE.md`
- [ ] `docs/MONITORING_GUIDE.md`
- [ ] `docs/DEPLOYMENT_GUIDE.md`
- [ ] `docs/TROUBLESHOOTING.md`

### √Ä Mettre √† Jour
- [ ] `README.md` (nouveau setup)
- [ ] `SETUP_GUIDE.md` (Redis, Prometheus)
- [ ] `API_DOCUMENTATION.md` (endpoints metrics)

---

## üéâ SUCCESS CRITERIA

Sprint 2 r√©ussi si :

1. ‚úÖ **Performance** : Latence moyenne <2s (actuellement ~3-5s)
2. ‚úÖ **Co√ªt** : R√©duction 70% appels API via cache
3. ‚úÖ **Qualit√©** : Coverage tests >80%
4. ‚úÖ **Observabilit√©** : Dashboard Grafana op√©rationnel
5. ‚úÖ **Automation** : CI/CD d√©ploie automatiquement

**Metric de succ√®s ultime :** 
Syst√®me peut g√©rer **100 corrections simultan√©es** sans d√©gradation performance.

---

## üë• √âQUIPE

**Dev Lead :** Amelia  
**Architect :** Winston  
**Product Owner :** Gregoire  
**QA :** Tests automatis√©s (CI/CD)

---

## üìû COMMUNICATION

**Daily Standup :** GitHub Discussions  
**Blockers :** Slack #dev-sprint2  
**Questions :** Ce chat ou documentation  

---

**üöÄ LET'S GO SPRINT 2 !**

*"Make it fast, make it reliable, make it observable."*

---

**üìÖ Cr√©√© :** 2026-01-10  
**üîÑ Derni√®re MAJ :** 2026-01-10  
**‚úçÔ∏è Auteur :** BMad Master + Amelia + Winston
