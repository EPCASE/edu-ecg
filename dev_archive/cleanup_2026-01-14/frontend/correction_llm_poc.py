"""
üß™ POC - Interface de Test Correction LLM
Interface Streamlit standalone pour tester le pipeline de correction

Auteur: Edu-ECG Team  
Date: 2026-01-10
Usage: streamlit run frontend/correction_llm_poc.py
"""

import streamlit as st
import sys
from pathlib import Path
import json
import os

# Charger variables d'environnement depuis .env
from dotenv import load_dotenv
project_root = Path(__file__).parent.parent
load_dotenv(project_root / ".env")

# Ajouter project root au path pour imports
sys.path.insert(0, str(project_root))

# Imports backend services
try:
    from backend.services.llm_service import LLMService
    from backend.scoring_service_llm import SemanticScorer
    from backend.feedback_service import FeedbackService
    from backend.services.llm_semantic_matcher import semantic_match, get_match_type_emoji, get_match_type_label
    LLM_AVAILABLE = True
    LLM_SEMANTIC_MATCHER_AVAILABLE = True
except ImportError as e:
    LLM_AVAILABLE = False
    LLM_SEMANTIC_MATCHER_AVAILABLE = False
    import_error = str(e)

# Charger ontologie pond√©r√©e OWL (prioritaire) ou fallback sur ancienne version
ONTOLOGY_MAPPING = None
WEIGHTED_ONTOLOGY = None

# 1. Charger ontologie OWL pond√©r√©e (source de v√©rit√©)
owl_mapping_file = project_root / "data" / "ontology_from_owl.json"
if owl_mapping_file.exists():
    with open(owl_mapping_file, 'r', encoding='utf-8') as f:
        WEIGHTED_ONTOLOGY = json.load(f)
        ONTOLOGY_MAPPING = WEIGHTED_ONTOLOGY  # Utiliser comme mapping principal

# 2. Fallback sur ancienne ontologie si OWL non disponible
if not ONTOLOGY_MAPPING:
    mapping_file = project_root / "data" / "epic1_ontology_mapping.json"
    if mapping_file.exists():
        with open(mapping_file, 'r', encoding='utf-8') as f:
            ONTOLOGY_MAPPING = json.load(f)

# Helper: Trouver un concept dans l'ontologie OWL par son label fran√ßais
def find_owl_concept(concept_text):
    """
    Cherche un concept dans l'ontologie OWL pond√©r√©e par son label fran√ßais
    
    Args:
        concept_text: Le texte du concept (ex: "nstemi", "bav 2 mobitz 1")
        
    Returns:
        dict ou None: {
            'ontology_id': str,
            'concept_name': str,
            'poids': int,
            'categorie': str,
            'synonymes': list,
            'implications': list
        }
    """
    if not WEIGHTED_ONTOLOGY:
        return None
        
    concept_lower = concept_text.lower().strip()
    
    # Chercher dans concept_mappings
    concept_mappings = WEIGHTED_ONTOLOGY.get('concept_mappings', {})
    
    # 1. Recherche exacte par concept_name (case-insensitive)
    for ontology_id, mapping in concept_mappings.items():
        concept_name = mapping.get('concept_name', '').lower()
        if concept_name == concept_lower:
            return {
                'ontology_id': ontology_id,
                'concept_name': mapping.get('concept_name'),
                'poids': mapping.get('poids', 1),
                'categorie': mapping.get('categorie', 'DESCRIPTEUR_ECG'),
                'synonymes': mapping.get('synonymes', []),
                'implications': mapping.get('implications', [])
            }
    
    # 2. Recherche par synonymes
    for ontology_id, mapping in concept_mappings.items():
        synonymes = [s.lower() for s in mapping.get('synonymes', [])]
        if concept_lower in synonymes:
            return {
                'ontology_id': ontology_id,
                'concept_name': mapping.get('concept_name'),
                'poids': mapping.get('poids', 1),
                'categorie': mapping.get('categorie', 'DESCRIPTEUR_ECG'),
                'synonymes': mapping.get('synonymes', []),
                'implications': mapping.get('implications', [])
            }
    
    # 3. Recherche partielle (contient)
    for ontology_id, mapping in concept_mappings.items():
        concept_name = mapping.get('concept_name', '').lower()
        if concept_lower in concept_name or concept_name in concept_lower:
            return {
                'ontology_id': ontology_id,
                'concept_name': mapping.get('concept_name'),
                'poids': mapping.get('poids', 1),
                'categorie': mapping.get('categorie', 'DESCRIPTEUR_ECG'),
                'synonymes': mapping.get('synonymes', []),
                'implications': mapping.get('implications', [])
            }
    
    # Pas trouv√© - retourner poids par d√©faut
    return {
        'ontology_id': concept_text.upper().replace(' ', '_'),
        'concept_name': concept_text,
        'poids': 1,  # Par d√©faut: descripteur
        'categorie': 'DESCRIPTEUR_ECG',
        'synonymes': [],
        'implications': []
    }

# Helper: Matching avec ontologie et synonymes
def match_concept_with_ontology(student_text, expected_concept, use_llm_semantic=True):
    """
    V√©rifie si le texte √©tudiant correspond au concept attendu
    en utilisant l'ontologie OWL pond√©r√©e (synonymes + labels)
    
    NOUVELLE ARCHITECTURE (2026-01-11) :
    Utilise SemanticScorer pour scoring hi√©rarchique directionnel
    - Diagnostic ‚Üí Signe = 100% (implication valid√©e)
    - Signe ‚Üí Diagnostic = 40% (incomplet)
    
    Returns: (match_found, match_type, matched_text, owl_concept, llm_result, score_percentage)
    - match_found: bool
    - match_type: 'exact'|'synonyme'|'implication'|'semantic'|'parent_concept'|'partial'
    - matched_text: le texte qui a match√©
    - owl_concept: dict avec poids et cat√©gorie
    - llm_result: dict r√©sultat LLM si utilis√©, None sinon
    - score_percentage: float (0-100) - score partiel si signe incomplet
    """
    student_lower = student_text.lower()
    concept_lower = expected_concept.lower()
    
    # Dictionnaire de synonymes suppl√©mentaires (en attendant enrichissement OWL)
    EXTRA_SYNONYMS = {
        "BAV 2 Mobitz 1": ["BAV2M1", "BAV 2 M1", "bav2 mobitz 1", "bav 2m1", "mobitz 1", "mobitz I", "wenckebach"],
        "BAV 2 Mobitz 2": ["BAV2M2", "BAV 2 M2", "bav2 mobitz 2", "bav 2m2", "mobitz 2", "mobitz II"],
        "BAV de type 1": ["BAV1", "BAV 1", "bav de type 1", "bav i", "bav premier degr√©"],
        "Rythme sinusal": ["sinusal", "RS", "rythme sinus", "sinusale"],
        "QRS fins": ["QRS fin", "QRS normal", "qrs normaux"],
        "QRS normal": ["QRS fins", "QRS fin", "qrs normaux"],
        "Bloc de branche gauche": ["BBG", "bbg complet"],
        "Bloc de branche droit": ["BBD", "bbd complet"],
        "Bloc fasciculaire ant√©rieur gauche": ["HBAG", "h√©mibloc ant√©rieur gauche", "hemibloc ant√©rieur gauche"],
    }
    
    # Trouver le concept dans l'ontologie OWL
    owl_concept = find_owl_concept(expected_concept)
    
    # ====================================================================
    # PHASE 0 : UTILISER SemanticScorer pour scoring hi√©rarchique
    # ====================================================================
    
    try:
        scorer = SemanticScorer()
        student_concept_dict = {'text': student_text, 'category': 'unknown'}
        expected_concept_dict = {'text': expected_concept, 'category': owl_concept.get('categorie', 'unknown') if owl_concept else 'unknown'}
        
        match_result = scorer._compare_concepts_llm(student_concept_dict, expected_concept_dict)
        
        # Si le score est > 0, c'est un match (m√™me partiel)
        if match_result.score > 0:
            match_type_map = {
                'exact': 'exact',
                'child': 'implication',  # Diagnostic ‚Üí Signe (100%)
                'partial': 'partial',     # Signe ‚Üí Diagnostic (40%)
                'parent': 'parent_concept',
                'sibling': 'semantic_sibling'
            }
            
            return (
                True,
                match_type_map.get(match_result.match_type.value, 'semantic'),
                match_result.student_concept,
                owl_concept,
                {'explanation': match_result.explanation, 'score': match_result.score},
                match_result.score  # Score partiel (0-100)
            )
    except Exception as e:
        print(f"‚ö†Ô∏è SemanticScorer error: {e}, falling back to legacy matching")
    
    # ====================================================================
    # PHASE 1 : MATCHING D√âTERMINISTE (rapide, gratuit, reproductible)
    # ====================================================================
    
    # Match exact direct
    if concept_lower in student_lower:
        return (True, 'exact', expected_concept, owl_concept, None, 100.0)
    
    # V√©rifier synonymes suppl√©mentaires
    if expected_concept in EXTRA_SYNONYMS:
        for syn in EXTRA_SYNONYMS[expected_concept]:
            if syn.lower() in student_lower:
                return (True, 'synonyme', syn, owl_concept, None, 100.0)
    
    # V√©rifier synonymes de l'ontologie OWL
    if owl_concept and owl_concept.get('synonymes'):
        for synonyme in owl_concept['synonymes']:
            if synonyme.lower() in student_lower:
                return (True, 'synonyme', synonyme, owl_concept, None, 100.0)
    
    # V√©rifier ontology_id (ex: "NSTEMI" pour "syndrome coronarien...")
    if owl_concept:
        ontology_id = owl_concept.get('ontology_id', '').lower().replace('_', ' ')
        if ontology_id in student_lower:
            return (True, 'ontology_id', owl_concept.get('ontology_id'), owl_concept, None, 100.0)
    
    # V√©rifier si l'√©tudiant a utilis√© un concept parent du concept attendu
    # Ex: √©tudiant dit "QRS normal" pour concept attendu "QRS fins"
    # D√âSACTIV√â: Cette logique est maintenant g√©r√©e par SemanticScorer
    # if WEIGHTED_ONTOLOGY:
    #     concept_mappings = WEIGHTED_ONTOLOGY.get('concept_mappings', {})
    #     
    #     # Chercher le concept attendu dans les implications d'autres concepts
    #     for concept_id, concept_data in concept_mappings.items():
    #         concept_name = concept_data.get('concept_name', '')
    #         
    #         # Si ce concept a le concept attendu dans ses implications (enfants)
    #         if expected_concept in concept_data.get('implications', []):
    #             # V√©rifier si l'√©tudiant a mentionn√© ce concept parent
    #             if concept_name.lower() in student_lower:
    #                 return (True, 'parent_concept', concept_name, owl_concept, None, 100.0)
    
    # ====================================================================
    # PHASE 2 : MATCHING S√âMANTIQUE LLM (si disponible et activ√©)
    # ====================================================================
    
    if use_llm_semantic and LLM_SEMANTIC_MATCHER_AVAILABLE:
        try:
            # Pr√©parer contexte ontologique pour le LLM
            ontology_context = None
            if owl_concept:
                ontology_context = {
                    'id': owl_concept.get('ontology_id'),
                    'name': owl_concept.get('concept_name'),
                    'synonyms': owl_concept.get('synonymes', []),
                    'category': owl_concept.get('categorie'),
                    'implications': owl_concept.get('implications', []),
                    'weight': owl_concept.get('poids', 1)
                }
            
            # Appeler le matching s√©mantique LLM
            llm_result = semantic_match(student_text, expected_concept, ontology_context)
            
            # Si LLM trouve un match, le retourner
            if llm_result.get('match'):
                return (
                    True, 
                    f"semantic_{llm_result.get('match_type')}", 
                    student_text, 
                    owl_concept, 
                    llm_result,
                    100.0  # LLM legacy donne toujours 100%
                )
        
        except Exception as e:
            # En cas d'erreur LLM, continuer sans (fallback gracieux)
            print(f"‚ö†Ô∏è Erreur LLM semantic matcher : {e}")
            pass
    
    # Pas de match trouv√© (ni d√©terministe ni LLM)
    return (False, None, None, owl_concept, None, 0.0)

def apply_implication_rules(matched_concepts, all_expected_concepts):
    """
    Applique les r√®gles d'implication automatique
    Si un diagnostic est identifi√©, valide automatiquement ses implications
    
    Returns: set of auto-validated concept names
    """
    auto_validated = set()
    
    if not ONTOLOGY_MAPPING:
        return auto_validated
    
    implication_rules = ONTOLOGY_MAPPING.get('implication_rules', {})
    concept_mappings = ONTOLOGY_MAPPING.get('concept_mappings', {})
    
    # Pour chaque concept match√© par l'√©tudiant
    for matched_concept in matched_concepts:
        # Trouver son mapping
        mapping_key = None
        for k in concept_mappings.keys():
            if k.lower() == matched_concept.lower():
                mapping_key = k
                break
        
        if not mapping_key:
            continue
            
        mapping = concept_mappings[mapping_key]
        ontology_id = mapping.get('ontology_id', '')
        
        # Si ce concept a des r√®gles d'implication
        if ontology_id in implication_rules:
            rule = implication_rules[ontology_id]
            auto_validate_ids = rule.get('auto_validate', [])
            
            # Pour chaque ID √† auto-valider, trouver les concepts correspondants
            for auto_id in auto_validate_ids:
                # Chercher dans les expected_concepts lesquels correspondent √† cet ID
                for expected in all_expected_concepts:
                    expected_mapping_key = None
                    for k in concept_mappings.keys():
                        if k.lower() == expected.lower():
                            expected_mapping_key = k
                            break
                    
                    if expected_mapping_key:
                        expected_mapping = concept_mappings[expected_mapping_key]
                        if expected_mapping.get('ontology_id', '') == auto_id:
                            auto_validated.add(expected)
    
    return auto_validated

def check_if_child_concept_used(expected_concept, student_answer):
    """
    V√©rifie si l'√©tudiant a utilis√© un concept enfant du concept attendu
    
    Args:
        expected_concept: Concept attendu (ex: "ECG normal")
        student_answer: R√©ponse compl√®te de l'√©tudiant
    
    Returns:
        (bool, list[str]): (True/False, liste des concepts enfants trouv√©s)
    """
    if not WEIGHTED_ONTOLOGY:
        return (False, [])
    
    # Trouver le mapping du concept attendu
    concept_mappings = WEIGHTED_ONTOLOGY.get('concept_mappings', {})
    
    expected_owl = None
    for concept_id, concept_data in concept_mappings.items():
        if concept_data.get('concept_name', '').lower() == expected_concept.lower():
            expected_owl = concept_data
            break
    
    if not expected_owl:
        return (False, [])
    
    # V√©rifier les implications (enfants dans la hi√©rarchie)
    implications = expected_owl.get('implications', [])
    if not implications:
        return (False, [])
    
    # Chercher si l'√©tudiant a mentionn√© un des enfants
    student_lower = student_answer.lower()
    found_children = []
    
    for child_name in implications:
        if child_name.lower() in student_lower:
            found_children.append(child_name)
            continue
        
        # V√©rifier aussi les synonymes de l'enfant
        child_owl = None
        for concept_id, concept_data in concept_mappings.items():
            if concept_data.get('concept_name', '').lower() == child_name.lower():
                child_owl = concept_data
                break
        
        if child_owl:
            for synonyme in child_owl.get('synonymes', []):
                if synonyme.lower() in student_lower:
                    found_children.append(child_name)
                    break
    
    return (len(found_children) > 0, found_children)

# Configuration page
st.set_page_config(
    page_title="üß™ POC - Correction LLM ECG",
    page_icon="ü´Ä",
    layout="wide"
)

# Style CSS
st.markdown("""
<style>
    .success-box {
        padding: 20px;
        background-color: #d4edda;
        border-left: 5px solid #28a745;
        border-radius: 5px;
        margin: 10px 0;
    }
    .warning-box {
        padding: 20px;
        background-color: #fff3cd;
        border-left: 5px solid #ffc107;
        border-radius: 5px;
        margin: 10px 0;
    }
    .error-box {
        padding: 20px;
        background-color: #f8d7da;
        border-left: 5px solid #dc3545;
        border-radius: 5px;
        margin: 10px 0;
    }
    .info-box {
        padding: 20px;
        background-color: #d1ecf1;
        border-left: 5px solid #17a2b8;
        border-radius: 5px;
        margin: 10px 0;
    }
    .stat-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 20px;
        border-radius: 10px;
        color: white;
        text-align: center;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
    }
    .stat-value {
        font-size: 48px;
        font-weight: bold;
        margin: 10px 0;
    }
</style>
""", unsafe_allow_html=True)

# Titre
st.title("üß™ POC - Syst√®me de Correction LLM")
st.markdown("**Proof of Concept** - Pipeline de correction automatique avec feedback p√©dagogique")

# V√©rifier d√©pendances
if not LLM_AVAILABLE:
    st.error(f"""
    ‚ùå **Erreur d'import des services backend**
    
    D√©tail: {import_error}
    
    **Solutions:**
    1. V√©rifier que les fichiers existent:
       - `backend/services/llm_service.py`
       - `backend/scoring_service_llm.py`
       - `backend/feedback_service.py`
    
    2. Installer d√©pendances:
       ```bash
       pip install openai rdflib
       ```
    """)
    st.stop()

# V√©rifier cl√© OpenAI
if 'OPENAI_API_KEY' not in os.environ:
    st.warning("""
    ‚ö†Ô∏è **OPENAI_API_KEY non configur√©e**
    
    Le feedback GPT-4o ne fonctionnera pas. Configurez dans `.env`:
    ```
    OPENAI_API_KEY=sk-proj-xxxxxxxxxxxxx
    ```
    
    Le scoring hi√©rarchique fonctionnera quand m√™me !
    """)

# Sidebar - Configuration
with st.sidebar:
    st.header("‚öôÔ∏è Configuration")
    
    # S√©lection cas test
    st.subheader("üìÅ Cas Test")
    
    # üÜï Charger cas disponibles - NOUVELLE PRIORIT√â: Sessions cr√©√©es + Epic 1 + Legacy
    ecg_sessions_dir = project_root / "data" / "ecg_sessions"
    ecg_cases_dir = project_root / "data" / "ecg_cases"
    epic1_file = project_root / "data" / "case_templates_epic1.json"
    test_cases_file = project_root / "data" / "test_cases.json"
    
    test_cases = []
    
    # üÜï 1. PRIORIT√â: Charger sessions cr√©√©es depuis ecg_session_builder
    if ecg_sessions_dir.exists():
        session_files = list(ecg_sessions_dir.glob("session_*.json"))
        for session_file in sorted(session_files, reverse=True):  # Plus r√©cents d'abord
            try:
                with open(session_file, 'r', encoding='utf-8') as f:
                    session_data = json.load(f)
                    
                    # Charger chaque cas de la session
                    for case_id in session_data.get('cases', []):
                        case_metadata_file = ecg_cases_dir / case_id / "metadata.json"
                        if case_metadata_file.exists():
                            with open(case_metadata_file, 'r', encoding='utf-8') as cf:
                                case_data = json.load(cf)
                                
                                # Convertir au format test_cases
                                test_cases.append({
                                    'case_id': case_data['case_id'],
                                    'title': f"[SESSION {session_data['name']}] {case_data.get('diagnostic_principal', case_id)}",
                                    'expected_answer': ", ".join(case_data.get('expected_concepts', [])),
                                    'expected_concepts': case_data.get('expected_concepts', []),
                                    'context': case_data.get('clinical_context', ''),
                                    'metadata': case_data.get('metadata', {}),
                                    'session_name': session_data['name'],
                                    'session_id': session_data['session_id']
                                })
            except Exception as e:
                st.sidebar.warning(f"‚ö†Ô∏è Erreur chargement session {session_file.name}: {e}")
    
    # 2. Charger Epic 1 templates
    if epic1_file.exists():
        with open(epic1_file, 'r', encoding='utf-8') as f:
            epic1_data = json.load(f)
            for template in epic1_data.get('templates', []):
                test_cases.append({
                    'case_id': template['case_id'],
                    'title': f"[EPIC1] {template['diagnostic_principal']}",
                    'expected_answer': ", ".join(template['expected_concepts']),
                    'expected_concepts': template['expected_concepts'],
                    'context': template.get('notes_pedagogiques', ''),
                    'metadata': template.get('metadata', {}),
                    'implications': template.get('implications', {}),
                    'niveau_difficulte': template.get('niveau_difficulte', 'moyen')
                })
    
    # 3. Charger test_cases.json legacy
    if test_cases_file.exists():
        with open(test_cases_file, 'r', encoding='utf-8') as f:
            legacy_cases = json.load(f)
            for case in legacy_cases:
                case['title'] = f"[LEGACY] {case.get('title', case['case_id'])}"
            test_cases.extend(legacy_cases)
    
    if test_cases:
        case_options = [case['case_id'] + ": " + case['title'] for case in test_cases]
        selected_case_idx = st.selectbox(
            "Choisir un cas",
            range(len(case_options)),
            format_func=lambda i: case_options[i]
        )
        
        selected_case = test_cases[selected_case_idx]
    else:
        st.info("""
        üìù Aucun cas test trouv√©.
        
        Cr√©ez `data/test_cases.json` avec vos annotations.
        
        Template disponible dans `data/test_cases_template.json`
        """)
        selected_case = None
    
    st.divider()
    
    # Param√®tres correction
    st.subheader("üéØ Param√®tres")
    
    student_level = st.select_slider(
        "Niveau √©tudiant",
        options=['beginner', 'intermediate', 'advanced'],
        value='intermediate',
        help="Adapte le ton du feedback"
    )
    
    use_llm_feedback = st.checkbox(
        "Feedback GPT-4o",
        value=True,
        help="D√©sactiver si pas de cl√© OpenAI"
    )
    
    use_llm_semantic = st.checkbox(
        "üß† Matching S√©mantique LLM",
        value=LLM_SEMANTIC_MATCHER_AVAILABLE,
        disabled=not LLM_SEMANTIC_MATCHER_AVAILABLE,
        help="Utilise GPT-4o pour comprendre variations linguistiques (BAV2M1, Sinusal, etc.). Le scoring reste g√©r√© par l'ontologie."
    )
    
    if use_llm_semantic and not LLM_SEMANTIC_MATCHER_AVAILABLE:
        st.warning("‚ö†Ô∏è LLM Semantic Matcher non disponible. Installer backend/services/llm_semantic_matcher.py")
    
    st.divider()
    
    # Stats POC
    st.subheader("üìä Stats Session")
    
    if 'corrections_count' not in st.session_state:
        st.session_state.corrections_count = 0
    
    st.metric("Corrections test√©es", st.session_state.corrections_count)

# Zone principale
tab1, tab2, tab3 = st.tabs(["üß™ Test Correction", "üìö Guide", "‚öôÔ∏è Diagnostic"])

with tab1:
    st.header("üß™ Tester la Correction")
    
    if selected_case:
        # Afficher infos cas
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.subheader(f"üìÑ Cas: {selected_case['title']}")
            st.markdown(f"**ID:** `{selected_case['case_id']}`")
            st.markdown(f"**Cat√©gorie:** {selected_case.get('category', 'Non sp√©cifi√©e')}")
            
            if 'description' in selected_case:
                with st.expander("üìñ Description du cas"):
                    st.info(selected_case['description'])
        
        with col2:
            # Concepts attendus
            st.subheader("‚úÖ Concepts Attendus")
            expected_concepts = selected_case['expected_concepts']
            
            for concept in expected_concepts:
                # Support both formats: string (Epic 1) or dict (legacy)
                if isinstance(concept, str):
                    # Format Epic 1: simple strings
                    st.markdown(f"üìå {concept}")
                else:
                    # Format legacy: dict with category
                    category_icon = {
                        'rhythm': 'ü´Ä',
                        'conduction': '‚ö°',
                        'morphology': 'üìà',
                        'measurement': 'üìè',
                        'pathology': 'ü©∫'
                    }.get(concept.get('category', ''), 'üìå')
                    
                    st.markdown(f"{category_icon} {concept['text']}")
        
        st.divider()
        
        # Zone saisie r√©ponse √©tudiant
        st.subheader("‚úçÔ∏è R√©ponse √âtudiant")
        
        # Exemples de r√©ponses rapides
        if selected_case['case_id'] == 'BAV1_BBG_002':
            st.caption("üí° Exemples de r√©ponses √† tester:")
            col_ex1, col_ex2, col_ex3 = st.columns(3)
            
            with col_ex1:
                if st.button("üìù R√©ponse compl√®te", use_container_width=True):
                    st.session_state.example_answer = """Rythme sinusal
Onde P normale
BAV 1er degr√©
Bloc de branche gauche complet"""
            
            with col_ex2:
                if st.button("üìù Sans diagnostics", use_container_width=True):
                    st.session_state.example_answer = """Rythme sinusal
Onde P normale
PR allong√©
QRS larges"""
            
            with col_ex3:
                if st.button("üìù Avec axe", use_container_width=True):
                    st.session_state.example_answer = """Rythme sinusal
Onde P normale
BAV 1er degr√©
Bloc de branche gauche complet
Axe normal"""
        
        elif selected_case['case_id'] == 'RYTHME_SINUSAL_001':
            st.caption("üí° Exemples de r√©ponses √† tester:")
            col_ex1, col_ex2 = st.columns(2)
            
            with col_ex1:
                if st.button("üìù ECG normal (global)", use_container_width=True):
                    st.session_state.example_answer = "ECG normal"
            
            with col_ex2:
                if st.button("üìù D√©tails complets", use_container_width=True):
                    st.session_state.example_answer = """Rythme sinusal
Fr√©quence cardiaque normale
PR normal
QRS fins
Axe normal
Pas d'anomalie de repolarisation"""
        
        # Zone de texte avec pr√©-remplissage si exemple s√©lectionn√©
        default_text = st.session_state.get('example_answer', '')
        student_answer = st.text_area(
            "Entrez votre interpr√©tation de l'ECG",
            value=default_text,
            placeholder="Exemple: Rythme sinusal, BAV 1er degr√©, PR prolong√© √† 220ms, axe normal...",
            height=150,
            help="D√©crivez tous les √©l√©ments ECG que vous identifiez",
            key="student_answer_input"
        )
        
        # Reset example apr√®s utilisation
        if 'example_answer' in st.session_state and student_answer != default_text:
            del st.session_state.example_answer
        
        # Bouton correction
        col1, col2, col3 = st.columns([1, 2, 1])
        
        with col2:
            correct_button = st.button(
                "üöÄ Corriger avec IA",
                type="primary",
                use_container_width=True,
                disabled=not student_answer
            )
        
        # Validation r√©ponse vide
        if correct_button:
            if not student_answer or len(student_answer.strip()) < 5:
                st.error("‚ö†Ô∏è **Veuillez entrer une r√©ponse** (minimum 5 caract√®res)")
                st.info("üí° D√©crivez ce que vous voyez sur l'ECG : rythme, intervalles, anomalies, etc.")
                st.stop()
        
        # Traitement correction
        if correct_button and student_answer:
            with st.spinner("ü§ñ Correction en cours..."):
                try:
                    # √âtape 1: Extraction concepts LLM
                    st.info("üîç √âtape 1/3: Extraction concepts avec LLM...")
                    llm_service = LLMService()
                    extraction_result = llm_service.extract_concepts(student_answer)
                    
                    student_concepts = extraction_result['concepts']
                    
                    # √âtape 2: Scoring avec ontologie
                    st.info("üìä √âtape 2/3: Scoring avec mapping ontologie...")
                    
                    # Convertir expected_concepts en liste de strings si n√©cessaire
                    expected_list = []
                    for concept in expected_concepts:
                        if isinstance(concept, str):
                            expected_list.append(concept)
                        else:
                            expected_list.append(concept.get('text', ''))
                    
                    # Matching avec ontologie et synonymes
                    matched_concepts = []
                    match_details = {}
                    concept_weights = {}  # Stocker les poids de chaque concept
                    concept_scores = {}   # üÜï Stocker les scores partiels
                    llm_matches = {}  # Stocker les r√©sultats LLM pour affichage
                    
                    for expected in expected_list:
                        match_found, match_type, matched_text, owl_concept, llm_result, score_pct = match_concept_with_ontology(
                            student_answer, expected, use_llm_semantic=use_llm_semantic
                        )
                        
                        # Stocker le poids du concept (m√™me si non match√©)
                        if owl_concept:
                            concept_weights[expected] = {
                                'poids': owl_concept.get('poids', 1),
                                'categorie': owl_concept.get('categorie', 'DESCRIPTEUR_ECG'),
                                'ontology_id': owl_concept.get('ontology_id', '')
                            }
                        else:
                            concept_weights[expected] = {'poids': 1, 'categorie': 'DESCRIPTEUR_ECG', 'ontology_id': ''}
                        
                        if match_found:
                            matched_concepts.append(expected)
                            match_details[expected] = {
                                'type': match_type,
                                'matched_text': matched_text,
                                'poids': concept_weights[expected]['poids'],
                                'categorie': concept_weights[expected]['categorie']
                            }
                            
                            # üÜï Stocker le score partiel (0-100)
                            concept_scores[expected] = score_pct
                            
                            # Stocker r√©sultat LLM si utilis√©
                            if llm_result:
                                llm_matches[expected] = llm_result
                    
                    # Appliquer r√®gles d'implication automatique
                    auto_validated = apply_implication_rules(matched_concepts, expected_list)
                    
                    # Combiner concepts match√©s + auto-valid√©s
                    all_validated = set(matched_concepts) | auto_validated
                    
                    # üÜï Calcul du score POND√âR√â avec scores partiels
                    # Calculer la somme des poids valid√©s (pond√©r√©s par le score partiel)
                    poids_valides = 0
                    for concept in all_validated:
                        poids = concept_weights.get(concept, {}).get('poids', 1)
                        score_pct = concept_scores.get(concept, 100.0) / 100.0  # üÜï Utiliser score partiel
                        poids_valides += poids * score_pct  # üÜï Pond√©rer par le score
                    
                    # Calculer la somme des poids attendus
                    poids_attendus = 0
                    for concept in expected_list:
                        poids_attendus += concept_weights.get(concept, {}).get('poids', 1)
                    
                    # Calcul pourcentage de base
                    base_percentage = (poids_valides / poids_attendus * 100) if poids_attendus > 0 else 0
                    
                    # Bonus si diagnostic principal (poids ‚â•3) identifi√©
                    has_diagnostic_principal = any(
                        concept_weights.get(c, {}).get('poids', 1) >= 3 
                        for c in all_validated
                    )
                    bonus_diagnostic = 0.15 if has_diagnostic_principal else 0
                    
                    # Score final avec bonus
                    percentage = min(100, base_percentage * (1 + bonus_diagnostic))
                    
                    # Stats d√©taill√©es pour affichage
                    total_expected = len(expected_list)
                    total_matched = len(all_validated)
                    exact_matches = len([c for c in matched_concepts if match_details.get(c, {}).get('type') == 'exact'])
                    synonyme_matches = len([c for c in matched_concepts if match_details.get(c, {}).get('type') == 'synonyme'])
                    auto_matches = len(auto_validated)
                    missing_concepts = total_expected - total_matched
                    
                    # Cr√©er un objet r√©sultat compatible avec feedback_service
                    class MatchType:
                        def __init__(self, value):
                            self.value = value
                    
                    class ConceptMatch:
                        def __init__(self, student_concept, expected_concept, match_type):
                            self.student_concept = student_concept
                            self.expected_concept = expected_concept
                            self.match_type = MatchType(match_type)
                    
                    class ScoringResult:
                        def __init__(self):
                            # Score pond√©r√©
                            self.percentage = percentage
                            self.base_percentage = base_percentage
                            self.bonus_diagnostic = bonus_diagnostic
                            self.poids_valides = poids_valides
                            self.poids_attendus = poids_attendus
                            
                            # Stats basiques
                            self.total_score = total_matched
                            self.max_score = total_expected
                            self.exact_matches = exact_matches
                            self.synonyme_matches = synonyme_matches
                            self.auto_validated_count = auto_matches
                            self.missing_concepts = missing_concepts
                            
                            # Donn√©es d√©taill√©es
                            self.matched_list = list(matched_concepts)
                            self.auto_validated_list = list(auto_validated)
                            self.match_details = match_details
                            self.concept_weights = concept_weights
                            self.expected_list = expected_list
                            
                            # Cr√©er liste de matches pour feedback_service
                            self.matches = []
                            
                            # Ajouter matches exacts et synonymes
                            for concept in matched_concepts:
                                match_type = match_details.get(concept, {}).get('type', 'exact')
                                self.matches.append(
                                    ConceptMatch(concept, concept, match_type)
                                )
                            
                            # Ajouter auto-valid√©s comme matches sp√©ciaux
                            for concept in auto_validated:
                                self.matches.append(
                                    ConceptMatch(concept, concept, 'implication')
                                )
                            
                            # Ajouter concepts manquants
                            missing = set(expected_list) - all_validated
                            for concept in missing:
                                self.matches.append(
                                    ConceptMatch('', concept, 'missing')
                                )
                    
                    scoring_result = ScoringResult()
                    
                    # √âtape 3: Feedback p√©dagogique
                    if use_llm_feedback and 'OPENAI_API_KEY' in os.environ:
                        st.info("üí¨ √âtape 3/3: G√©n√©ration feedback GPT-4o...")
                        feedback_service = FeedbackService()
                        feedback = feedback_service.generate_feedback(
                            case_title=selected_case['title'],
                            student_answer=student_answer,
                            scoring_result=scoring_result,
                            student_level=student_level
                        )
                    else:
                        feedback = None
                    
                    # Incr√©menter compteur
                    st.session_state.corrections_count += 1
                    
                    # Affichage r√©sultats
                    st.success("‚úÖ Correction termin√©e !")
                    
                    st.divider()
                    
                    # Score global
                    st.subheader("üìä R√©sultat Global")
                    
                    col1, col2, col3, col4 = st.columns(4)
                    
                    with col1:
                        st.markdown(f"""
                        <div class="stat-card">
                            <div>Score Global</div>
                            <div class="stat-value">{scoring_result.percentage:.1f}%</div>
                            <div>{scoring_result.poids_valides:.0f} / {scoring_result.poids_attendus:.0f} points pond√©r√©s</div>
                        </div>
                        """, unsafe_allow_html=True)
                    
                    with col2:
                        bonus_display = f"+{scoring_result.bonus_diagnostic*100:.0f}%" if scoring_result.bonus_diagnostic > 0 else "Aucun"
                        bonus_color = "#28a745" if scoring_result.bonus_diagnostic > 0 else "#6c757d"
                        st.markdown(f"""
                        <div class="stat-card" style="background: linear-gradient(135deg, {bonus_color} 0%, {bonus_color}dd 100%);">
                            <div>Bonus Diagnostic</div>
                            <div class="stat-value">{bonus_display}</div>
                            <div>{'üéØ Diagnostic identifi√©' if scoring_result.bonus_diagnostic > 0 else '‚ö™ Diagnostic manqu√©'}</div>
                        </div>
                        """, unsafe_allow_html=True)
                    
                    with col3:
                        st.markdown(f"""
                        <div class="stat-card" style="background: linear-gradient(135deg, #11998e 0%, #38ef7d 100%);">
                            <div>Concepts Exacts</div>
                            <div class="stat-value">{scoring_result.exact_matches}</div>
                            <div>‚úÖ Parfait</div>
                        </div>
                        """, unsafe_allow_html=True)
                    
                    with col4:
                        st.markdown(f"""
                        <div class="stat-card" style="background: linear-gradient(135deg, #ee0979 0%, #ff6a00 100%);">
                            <div>Concepts Manquants</div>
                            <div class="stat-value">{scoring_result.missing_concepts}</div>
                            <div>‚ùå √Ä revoir</div>
                        </div>
                        """, unsafe_allow_html=True)
                    
                    st.divider()
                    
                    # D√©tails concepts avec mapping ontologie
                    st.subheader("üîç D√©tails par Concept (Scoring Pond√©r√©)")
                    
                    # Couleurs par cat√©gorie
                    categorie_colors = {
                        'DIAGNOSTIC_URGENT': ('#D32F2F', 'üö®'),
                        'DIAGNOSTIC_MAJEUR': ('#F57C00', '‚ö°'),
                        'SIGNE_ECG_PATHOLOGIQUE': ('#FFA726', '‚ö†Ô∏è'),
                        'DESCRIPTEUR_ECG': ('#66BB6A', 'üìù')
                    }
                    
                    # Afficher concepts match√©s
                    for expected in scoring_result.expected_list:
                        weight_info = scoring_result.concept_weights.get(expected, {})
                        poids = weight_info.get('poids', 1)
                        categorie = weight_info.get('categorie', 'DESCRIPTEUR_ECG')
                        color, icon = categorie_colors.get(categorie, ('#66BB6A', 'üìù'))
                        
                        if expected in scoring_result.matched_list:
                            # Concept trouv√© par l'√©tudiant
                            details = scoring_result.match_details.get(expected, {})
                            match_type = details.get('type', 'exact')
                            matched_text = details.get('matched_text', expected)
                            
                            check_icon = '‚úÖ' if match_type == 'exact' else 'üîç'
                            type_label = {
                                'exact': 'Match exact',
                                'synonyme': 'Synonyme reconnu',
                                'ontology_id': 'ID ontologie',
                                'semantic': 'Match s√©mantique',
                                'semantic_exact': 'üéØ Match s√©mantique exact (LLM)',
                                'semantic_synonym': 'üîÑ Synonyme s√©mantique (LLM)',
                                'semantic_abbreviation': 'üìù Abr√©viation reconnue (LLM)',
                                'semantic_equivalent': '‚âà √âquivalent s√©mantique (LLM)',
                                'semantic_parent': '‚¨ÜÔ∏è Concept parent (LLM)',
                                'semantic_child': '‚¨áÔ∏è Concept enfant (LLM)',
                                'parent_concept': '‚¨ÜÔ∏è Concept parent (hi√©rarchie)'
                            }.get(match_type, 'Match')
                            
                            # V√©rifier si matching LLM utilis√©
                            llm_info = ""
                            if expected in llm_matches:
                                llm_result = llm_matches[expected]
                                llm_emoji = get_match_type_emoji(llm_result.get('match_type', ''))
                                llm_confidence = llm_result.get('confidence', 0)
                                llm_explanation = llm_result.get('explanation', '')
                                llm_info = f"""<br>
                                <div style="background-color: #e7f3ff; padding: 8px; margin-top: 6px; border-radius: 4px; border-left: 3px solid #17a2b8;">
                                    üß† <strong>LLM Semantic Matcher</strong> ({llm_confidence}% confiance)<br>
                                    {llm_emoji} {llm_explanation}
                                </div>"""
                            
                            st.markdown(f"""
                            <div class="success-box" style="border-left-color: {color};">
                                {check_icon} <strong>{expected}</strong> - {poids} pts {icon}<br>
                                Type: {type_label} - Texte trouv√©: "{matched_text}"<br>
                                <small>Cat√©gorie: {categorie.replace('_', ' ')}</small>
                                {llm_info}
                            </div>
                            """, unsafe_allow_html=True)
                        
                        elif expected in scoring_result.auto_validated_list:
                            # Concept auto-valid√© par implication
                            st.markdown(f"""
                            <div class="success-box" style="background-color: #e7f3ff; border-left-color: {color};">
                                ü§ñ <strong>{expected}</strong> - {poids} pts {icon} (Auto-valid√©)<br>
                                Valid√© automatiquement par r√®gle d'implication diagnostique<br>
                                <small>Cat√©gorie: {categorie.replace('_', ' ')}</small>
                            </div>
                            """, unsafe_allow_html=True)
                        
                        else:
                            # Concept manquant
                            # V√©rifier si l'√©tudiant a utilis√© un concept enfant
                            has_child, child_concepts = check_if_child_concept_used(expected, student_answer)
                            
                            # Afficher suggestion de synonymes si mapping existe
                            suggestion = ""
                            owl_concept = find_owl_concept(expected)
                            if owl_concept and owl_concept.get('synonymes'):
                                synonymes = owl_concept['synonymes']
                                if synonymes:
                                    suggestion = f"<br><em>üí° Synonymes accept√©s: {', '.join(synonymes[:3])}</em>"
                            
                            # Message p√©dagogique si concepts enfants trouv√©s
                            child_message = ""
                            if has_child and child_concepts:
                                child_list = ', '.join([f"<strong>{c}</strong>" for c in child_concepts[:3]])
                                child_message = f"""<br>
                                <div style="background-color: #fff3cd; padding: 10px; margin-top: 8px; border-radius: 4px; border-left: 3px solid #ffc107;">
                                    ‚ö†Ô∏è <strong>Attention p√©dagogique :</strong><br>
                                    Vous avez mentionn√© {child_list} qui {'font' if len(child_concepts) > 1 else 'fait'} partie de "<strong>{expected}</strong>".<br>
                                    Ces √©l√©ments sont corrects mais <strong>ne remplacent pas</strong> le diagnostic complet attendu.<br>
                                    üí° <em>Pensez √† donner la r√©ponse la plus compl√®te et synth√©tique.</em>
                                </div>"""
                            
                            st.markdown(f"""
                            <div class="error-box" style="border-left-color: {color};">
                                ‚ùå <strong>{expected}</strong> - <span style="color: {color};">-{poids} pts {icon}</span><br>
                                Ce concept n'a pas √©t√© retrouv√© dans votre r√©ponse{suggestion}
                                {child_message}
                                <br><small>Cat√©gorie: {categorie.replace('_', ' ')}</small>
                            </div>
                            """, unsafe_allow_html=True)
                    
                    # Stats du matching ontologie
                    if WEIGHTED_ONTOLOGY:
                        llm_stats = ""
                        if llm_matches:
                            llm_count = len(llm_matches)
                            llm_avg_confidence = sum(r.get('confidence', 0) for r in llm_matches.values()) / llm_count if llm_count > 0 else 0
                            llm_stats = f"""
                        - üß† Matches LLM s√©mantiques: {llm_count} (confiance moyenne: {llm_avg_confidence:.0f}%)"""
                        
                        st.info(f"""
                        üìö **Scoring avec Ontologie OWL Pond√©r√©e**  
                        - ‚öñÔ∏è Score: {scoring_result.base_percentage:.1f}% (base) + {scoring_result.bonus_diagnostic*100:.0f}% (bonus) = **{scoring_result.percentage:.1f}%**
                        - üéØ Poids valid√©s: {scoring_result.poids_valides:.0f} / {scoring_result.poids_attendus:.0f} points
                        - ‚úÖ Match exacts: {scoring_result.exact_matches}  
                        - üîç Synonymes reconnus: {scoring_result.synonyme_matches}  
                        - ü§ñ Auto-valid√©s (implications): {scoring_result.auto_validated_count}{llm_stats}  
                        - üìä Ontologie: {sum(len(cat['concepts']) for cat in WEIGHTED_ONTOLOGY['concept_categories'].values())} concepts avec poids
                        """)
                    elif ONTOLOGY_MAPPING:
                        st.info(f"""
                        üìö **Scoring avec ontologie activ√©**  
                        - Match exacts: {scoring_result.exact_matches}  
                        - Synonymes reconnus: {scoring_result.synonyme_matches}  
                        - Auto-valid√©s (implications): {scoring_result.auto_validated_count}  
                        - Mapping: {len(ONTOLOGY_MAPPING.get('concept_mappings', {}))} concepts ontologie
                        """)
                    
                    
                    # Feedback p√©dagogique
                    if feedback:
                        st.divider()
                        st.subheader("üí¨ Feedback P√©dagogique")
                        
                        st.markdown(f"**{feedback.summary}**")
                        
                        if feedback.strengths:
                            st.success("**‚úÖ Points Forts**\n\n" + "\n".join(f"- {s}" for s in feedback.strengths))
                        
                        if feedback.missing_concepts:
                            st.warning("**üìö √Ä Apprendre**\n\n" + "\n".join(f"- {m}" for m in feedback.missing_concepts))
                        
                        if feedback.errors:
                            st.error("**‚ùå Erreurs √† Corriger**\n\n" + "\n".join(f"- {e}" for e in feedback.errors))
                        
                        st.info(f"**üí° Conseil**\n\n{feedback.advice}")
                        
                        st.markdown(f"**üéØ Prochaines √âtapes**\n\n{feedback.next_steps}")
                    
                except Exception as e:
                    st.error(f"""
                    ‚ùå **Erreur lors de la correction**
                    
                    ```
                    {str(e)}
                    ```
                    
                    V√©rifiez:
                    1. Cl√© OPENAI_API_KEY configur√©e
                    2. Services backend accessibles
                    3. Logs dans terminal
                    """)
                    
                    import traceback
                    with st.expander("üêõ Stack trace compl√®te"):
                        st.code(traceback.format_exc())
    
    else:
        st.warning("Aucun cas test s√©lectionn√©. Chargez `data/test_cases.json` ou cr√©ez-en un.")

with tab2:
    st.header("üìö Guide d'Utilisation")
    
    st.markdown("""
    ## üéØ Objectif du POC
    
    Ce POC permet de tester le **pipeline de correction automatique LLM** avant int√©gration compl√®te.
    
    ### üîÑ Pipeline en 3 √âtapes
    
    1. **Extraction Concepts (LLM)**
       - Utilise GPT-4o pour extraire concepts m√©dicaux
       - Cat√©gorise : rhythm, conduction, morphology, measurement, pathology
       - Fallback regex si API √©choue
    
    2. **Scoring Hi√©rarchique**
       - Compare r√©ponse √©tudiant vs attendu
       - Scores: Exact (100 pts), Child (85-90), Parent (60-80), Missing (0)
       - Pond√©ration par cat√©gorie (rhythm √ó1.2, measurement √ó0.8)
    
    3. **Feedback P√©dagogique (GPT-4o)**
       - G√©n√®re feedback personnalis√© et bienveillant
       - Adapte ton selon niveau (beginner/intermediate/advanced)
       - Structure: Points forts ‚Üí √Ä am√©liorer ‚Üí Conseil ‚Üí Prochaines √©tapes
    
    ### üìù Comment Annoter un Cas
    
    1. Cr√©ez/√©ditez `data/test_cases.json`
    2. Format:
    ```json
    [
      {
        "case_id": "BAV1_001",
        "title": "BAV 1er degr√© simple",
        "category": "conduction",
        "description": "ECG montrant BAV 1er degr√© isol√©",
        "expected_concepts": [
          {"text": "Rythme sinusal", "category": "rhythm"},
          {"text": "BAV 1er degr√©", "category": "conduction"},
          {"text": "PR > 200ms", "category": "measurement"}
        ]
      }
    ]
    ```
    
    ### ‚úÖ M√©triques de Validation
    
    - **Precision**: % concepts corrects parmi ceux identifi√©s
    - **Recall**: % concepts attendus trouv√©s
    - **F1-Score**: Moyenne harmonique Precision/Recall
    - **Cible POC**: F1 > 70%
    - **Cible Production**: F1 > 80%
    
    ### üöÄ Prochaines √âtapes
    
    - **Semaine 1**: Test 3-5 cas, d√©mo informelle
    - **Semaine 2**: 10 cas annot√©s, m√©triques, d√©mo formelle
    - **Semaine 3-4**: Backend PostgreSQL, module progression
    """)

with tab3:
    st.header("‚öôÔ∏è Diagnostic Syst√®me")
    
    # V√©rifier services
    st.subheader("üîç Services Backend")
    
    services_status = {
        "LLM Service": Path(project_root / "backend" / "services" / "llm_service.py").exists(),
        "Ontology Service": Path(project_root / "backend" / "ontology_service.py").exists(),
        "Scoring Service (LLM)": Path(project_root / "backend" / "scoring_service_llm.py").exists(),
        "Feedback Service": Path(project_root / "backend" / "feedback_service.py").exists()
    }
    
    for service, status in services_status.items():
        if status:
            st.success(f"‚úÖ {service}")
        else:
            st.error(f"‚ùå {service}")
    
    st.divider()
    
    # V√©rifier environnement
    st.subheader("üîê Variables d'Environnement")
    
    env_vars = {
        "OPENAI_API_KEY": 'OPENAI_API_KEY' in os.environ,
        "REDIS_URL": 'REDIS_URL' in os.environ,
        "DATABASE_URL": 'DATABASE_URL' in os.environ
    }
    
    for var, status in env_vars.items():
        if status:
            st.success(f"‚úÖ {var} configur√©e")
        else:
            st.warning(f"‚ö†Ô∏è {var} non configur√©e (optionnel pour POC)")
    
    st.divider()
    
    # V√©rifier donn√©es
    st.subheader("üìÅ Fichiers de Donn√©es")
    
    data_files = {
        "test_cases.json": Path(project_root / "data" / "test_cases.json").exists(),
        "ontologie.owx": Path(project_root / "data" / "ontologie.owx").exists()
    }
    
    for file, status in data_files.items():
        if status:
            st.success(f"‚úÖ {file}")
        else:
            st.info(f"‚ÑπÔ∏è {file} - Cr√©er pour tester")

# Footer
st.divider()
st.markdown("""
<div style="text-align: center; color: #666; padding: 20px;">
    ü´Ä <strong>Edu-ECG POC</strong> - Syst√®me de Correction LLM<br>
    Semaine 1 - Proof of Concept<br>
    <em>D√©velopp√© avec BMad Method - Sc√©nario C Hybride Pragmatique</em>
</div>
""", unsafe_allow_html=True)
