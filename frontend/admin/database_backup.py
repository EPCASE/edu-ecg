"""
ğŸ”„ SystÃ¨me de Backup et Export/Import pour Base de DonnÃ©es ECG
Sauvegarde, restauration et migration des donnÃ©es
"""

import streamlit as st
import json
import zipfile
import shutil
from pathlib import Path
from datetime import datetime
import os
import pandas as pd

def display_backup_system():
    """Interface systÃ¨me de backup et export/import"""
    
    st.markdown("### ğŸ’¾ SystÃ¨me de Backup et Export/Import")
    
    tab1, tab2, tab3 = st.tabs(["ğŸ“¤ Export/Backup", "ğŸ“¥ Import/Restauration", "ğŸ“Š Gestion Backups"])
    
    with tab1:
        display_export_interface()
    
    with tab2:
        display_import_interface()
    
    with tab3:
        display_backup_management()

def display_export_interface():
    """Interface d'export et backup"""
    
    st.markdown("#### ğŸ“¤ Export de la Base de DonnÃ©es")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("##### ğŸ¯ Export SÃ©lectif")
        
        # SÃ©lection des cas Ã  exporter
        available_cases = get_available_cases()
        
        if not available_cases:
            st.warning("ğŸ“­ Aucun cas disponible pour export")
            return
        
        selected_cases = st.multiselect(
            "SÃ©lectionner les cas Ã  exporter :",
            options=[case['case_id'] for case in available_cases],
            format_func=lambda x: f"ğŸ“‹ {x}",
            help="Choisir les cas ECG Ã  inclure dans l'export"
        )
        
        # Options d'export
        st.markdown("##### âš™ï¸ Options d'Export")
        
        include_images = st.checkbox("ğŸ“· Inclure images ECG", value=True, 
                                   help="Exporter les fichiers images avec mÃ©tadonnÃ©es")
        include_annotations = st.checkbox("ğŸ·ï¸ Inclure annotations", value=True,
                                        help="Exporter toutes les annotations")
        include_sessions = st.checkbox("ğŸ“š Inclure sessions", value=False,
                                     help="Exporter les sessions d'exercices liÃ©es")
        
        # Format d'export
        export_format = st.selectbox(
            "ğŸ“ Format d'export :",
            ["ZIP Archive", "JSON MÃ©tadonnÃ©es seules", "CSV Tableau"],
            help="Choisir le format de sortie"
        )
        
        if st.button("ğŸš€ **CrÃ©er Export**", type="primary", use_container_width=True):
            if selected_cases:
                create_export(selected_cases, include_images, include_annotations, 
                            include_sessions, export_format)
            else:
                st.warning("âš ï¸ SÃ©lectionner au moins un cas")
    
    with col2:
        st.markdown("##### ğŸ’¾ Backup Complet")
        
        st.info("""
        **Backup automatique inclut :**
        - ğŸ“‹ Tous les cas ECG
        - ğŸ·ï¸ Toutes les annotations 
        - ğŸ“š Sessions utilisateur
        - âš™ï¸ Configuration systÃ¨me
        - ğŸ‘¥ Profils utilisateurs
        """)
        
        backup_name = st.text_input(
            "Nom du backup :",
            value=f"backup_ecg_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            help="Nom personnalisÃ© pour le backup"
        )
        
        if st.button("ğŸ’¾ **CrÃ©er Backup Complet**", type="secondary", use_container_width=True):
            create_full_backup(backup_name)

def display_import_interface():
    """Interface d'import et restauration"""
    
    st.markdown("#### ğŸ“¥ Import et Restauration")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("##### ğŸ“¤ Import de Cas ECG")
        
        uploaded_file = st.file_uploader(
            "Fichier d'import :",
            type=['zip', 'json'],
            help="Fichier ZIP ou JSON exportÃ© depuis Edu-CG"
        )
        
        if uploaded_file:
            st.success(f"âœ… Fichier chargÃ© : {uploaded_file.name}")
            
            # Options d'import
            import_mode = st.selectbox(
                "Mode d'import :",
                ["Ajouter aux cas existants", "Remplacer cas existants", "Import sÃ©lectif"],
                help="Comportement en cas de conflit"
            )
            
            if st.button("ğŸ“¥ **Importer**", type="primary"):
                process_import(uploaded_file, import_mode)
    
    with col2:
        st.markdown("##### ğŸ”„ Restauration Backup")
        
        # Liste des backups disponibles
        backups_dir = Path("backups")
        if backups_dir.exists():
            backup_files = list(backups_dir.glob("*.zip"))
            
            if backup_files:
                selected_backup = st.selectbox(
                    "SÃ©lectionner backup :",
                    options=backup_files,
                    format_func=lambda x: f"ğŸ’¾ {x.name} ({get_file_size(x)})",
                    help="Choisir le backup Ã  restaurer"
                )
                
                st.warning("âš ï¸ **ATTENTION** : La restauration remplacera toutes les donnÃ©es actuelles !")
                
                confirm_restore = st.checkbox("Je confirme vouloir restaurer ce backup")
                
                if st.button("ğŸ”„ **Restaurer**", disabled=not confirm_restore):
                    restore_backup(selected_backup)
            else:
                st.info("ğŸ“­ Aucun backup disponible")
        else:
            st.info("ğŸ“ Dossier backup non trouvÃ©")

def display_backup_management():
    """Gestion des backups existants"""
    
    st.markdown("#### ğŸ“Š Gestion des Backups")
    
    backups_dir = Path("backups")
    
    if not backups_dir.exists():
        backups_dir.mkdir(exist_ok=True)
        st.info("ğŸ“ Dossier backup crÃ©Ã©")
        return
    
    backup_files = list(backups_dir.glob("*.zip"))
    
    if not backup_files:
        st.info("ğŸ“­ Aucun backup disponible")
        return
    
    # Tableau des backups
    st.markdown("##### ğŸ“‹ Backups Disponibles")
    
    backup_data = []
    for backup_file in backup_files:
        stat = backup_file.stat()
        backup_data.append({
            'Nom': backup_file.name,
            'Taille': get_file_size(backup_file),
            'Date': datetime.fromtimestamp(stat.st_mtime).strftime("%d/%m/%Y %H:%M"),
            'Chemin': str(backup_file)
        })
    
    df_backups = pd.DataFrame(backup_data)
    
    # Affichage avec actions
    for idx, backup in df_backups.iterrows():
        col1, col2, col3, col4 = st.columns([3, 1, 1, 1])
        
        with col1:
            st.markdown(f"**ğŸ“¦ {backup['Nom']}**")
            st.caption(f"ğŸ“… {backup['Date']} â€¢ ğŸ’¾ {backup['Taille']}")
        
        with col2:
            if st.button("ğŸ“¥", key=f"restore_{idx}", help="Restaurer"):
                st.session_state[f"confirm_restore_{idx}"] = True
        
        with col3:
            if st.button("ğŸ“‹", key=f"info_{idx}", help="Informations"):
                show_backup_info(backup['Chemin'])
        
        with col4:
            if st.button("ğŸ—‘ï¸", key=f"delete_{idx}", help="Supprimer"):
                st.session_state[f"confirm_delete_{idx}"] = True
        
        # Gestion confirmations
        if st.session_state.get(f"confirm_restore_{idx}"):
            handle_restore_confirmation(backup['Chemin'], idx)
        
        if st.session_state.get(f"confirm_delete_{idx}"):
            handle_delete_confirmation(backup['Chemin'], idx)
        
        st.markdown("---")

def get_available_cases():
    """RÃ©cupÃ¨re liste des cas disponibles"""
    
    cases = []
    cases_dir = Path("data/ecg_cases")
    
    if cases_dir.exists():
        for case_dir in cases_dir.iterdir():
            if case_dir.is_dir():
                cases.append({
                    'case_id': case_dir.name,
                    'path': case_dir
                })
    
    return cases

def create_export(selected_cases, include_images, include_annotations, include_sessions, export_format):
    """CrÃ©e export sÃ©lectif"""
    
    try:
        export_dir = Path("exports")
        export_dir.mkdir(exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        if export_format == "ZIP Archive":
            export_path = export_dir / f"export_ecg_{timestamp}.zip"
            create_zip_export(selected_cases, export_path, include_images, include_annotations)
            
        elif export_format == "JSON MÃ©tadonnÃ©es seules":
            export_path = export_dir / f"metadata_ecg_{timestamp}.json"
            create_json_export(selected_cases, export_path)
            
        elif export_format == "CSV Tableau":
            export_path = export_dir / f"tableau_ecg_{timestamp}.csv"
            create_csv_export(selected_cases, export_path)
        
        st.success(f"âœ… Export crÃ©Ã© : {export_path.name}")
        
        # Bouton de tÃ©lÃ©chargement
        with open(export_path, 'rb') as f:
            st.download_button(
                label="ğŸ“¥ TÃ©lÃ©charger Export",
                data=f.read(),
                file_name=export_path.name,
                mime='application/octet-stream'
            )
            
    except Exception as e:
        st.error(f"âŒ Erreur export : {e}")

def create_zip_export(selected_cases, export_path, include_images, include_annotations):
    """CrÃ©e export ZIP"""
    
    with zipfile.ZipFile(export_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
        for case_id in selected_cases:
            case_dir = Path("data/ecg_cases") / case_id
            
            if case_dir.exists():
                # MÃ©tadonnÃ©es
                metadata_file = case_dir / "metadata.json"
                if metadata_file.exists():
                    zipf.write(metadata_file, f"{case_id}/metadata.json")
                
                # Images ECG
                if include_images:
                    for img_file in case_dir.glob("*.png"):
                        zipf.write(img_file, f"{case_id}/{img_file.name}")
                    for img_file in case_dir.glob("*.jpg"):
                        zipf.write(img_file, f"{case_id}/{img_file.name}")

def create_json_export(selected_cases, export_path):
    """CrÃ©e export JSON mÃ©tadonnÃ©es"""
    
    export_data = {
        'export_info': {
            'date': datetime.now().isoformat(),
            'version': '1.0',
            'cases_count': len(selected_cases)
        },
        'cases': []
    }
    
    for case_id in selected_cases:
        case_dir = Path("data/ecg_cases") / case_id
        metadata_file = case_dir / "metadata.json"
        
        if metadata_file.exists():
            with open(metadata_file, 'r', encoding='utf-8') as f:
                case_data = json.load(f)
                export_data['cases'].append(case_data)
    
    with open(export_path, 'w', encoding='utf-8') as f:
        json.dump(export_data, f, indent=2, ensure_ascii=False)

def create_csv_export(selected_cases, export_path):
    """CrÃ©e export CSV tableau"""
    
    cases_data = []
    
    for case_id in selected_cases:
        case_dir = Path("data/ecg_cases") / case_id
        metadata_file = case_dir / "metadata.json"
        
        if metadata_file.exists():
            with open(metadata_file, 'r', encoding='utf-8') as f:
                metadata = json.load(f)
                
                cases_data.append({
                    'Case ID': case_id,
                    'Nom': metadata.get('name', ''),
                    'Description': metadata.get('description', ''),
                    'CatÃ©gorie': metadata.get('category', ''),
                    'DifficultÃ©': metadata.get('difficulty', ''),
                    'Date CrÃ©ation': metadata.get('created_date', ''),
                    'Annotations': len(metadata.get('annotations', []))
                })
    
    df = pd.DataFrame(cases_data)
    df.to_csv(export_path, index=False, encoding='utf-8')

def create_full_backup(backup_name):
    """CrÃ©e backup complet du systÃ¨me"""
    
    try:
        backups_dir = Path("backups")
        backups_dir.mkdir(exist_ok=True)
        
        backup_path = backups_dir / f"{backup_name}.zip"
        
        with zipfile.ZipFile(backup_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
            # Cas ECG
            cases_dir = Path("data/ecg_cases")
            if cases_dir.exists():
                for file in cases_dir.rglob("*"):
                    if file.is_file():
                        zipf.write(file, f"ecg_cases/{file.relative_to(cases_dir)}")
            
            # Sessions
            sessions_dir = Path("data/ecg_sessions")
            if sessions_dir.exists():
                for file in sessions_dir.rglob("*"):
                    if file.is_file():
                        zipf.write(file, f"ecg_sessions/{file.relative_to(sessions_dir)}")
            
            # Profils utilisateurs
            users_dir = Path("users")
            if users_dir.exists():
                for file in users_dir.rglob("*"):
                    if file.is_file():
                        zipf.write(file, f"users/{file.relative_to(users_dir)}")
            
            # Ontologie
            ontology_file = Path("data/ontologie.owx")
            if ontology_file.exists():
                zipf.write(ontology_file, "data/ontologie.owx")
        
        file_size = get_file_size(backup_path)
        st.success(f"âœ… Backup crÃ©Ã© : {backup_path.name} ({file_size})")
        
    except Exception as e:
        st.error(f"âŒ Erreur backup : {e}")

def process_import(uploaded_file, import_mode):
    """Traite import de fichier"""
    
    try:
        with st.spinner("ğŸ“¥ Import en cours..."):
            # CrÃ©er dossier temporaire
            temp_dir = Path("temp_import")
            temp_dir.mkdir(exist_ok=True)
            
            # Sauvegarder fichier uploadÃ©
            temp_file = temp_dir / uploaded_file.name
            with open(temp_file, 'wb') as f:
                f.write(uploaded_file.read())
            
            # Traiter selon le type
            if uploaded_file.name.endswith('.zip'):
                process_zip_import(temp_file, import_mode)
            elif uploaded_file.name.endswith('.json'):
                process_json_import(temp_file, import_mode)
            
            # Nettoyage
            shutil.rmtree(temp_dir)
        
        st.success("âœ… Import terminÃ© avec succÃ¨s !")
        
    except Exception as e:
        st.error(f"âŒ Erreur import : {e}")

def process_zip_import(zip_file, import_mode):
    """Traite import ZIP"""
    
    cases_dir = Path("data/ecg_cases")
    cases_dir.mkdir(exist_ok=True)
    
    with zipfile.ZipFile(zip_file, 'r') as zipf:
        zipf.extractall("temp_extract")
        
        extract_dir = Path("temp_extract")
        
        # Traiter chaque cas
        for case_folder in extract_dir.iterdir():
            if case_folder.is_dir():
                target_dir = cases_dir / case_folder.name
                
                if target_dir.exists() and import_mode == "Ajouter aux cas existants":
                    st.warning(f"âš ï¸ Cas {case_folder.name} existe dÃ©jÃ , ignorÃ©")
                    continue
                
                # Copier le cas
                if target_dir.exists():
                    shutil.rmtree(target_dir)
                
                shutil.copytree(case_folder, target_dir)
                st.info(f"ğŸ“‹ Cas importÃ© : {case_folder.name}")
        
        # Nettoyage
        shutil.rmtree(extract_dir)

def process_json_import(json_file, import_mode):
    """Traite import JSON mÃ©tadonnÃ©es"""
    
    with open(json_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    cases_dir = Path("data/ecg_cases")
    cases_dir.mkdir(exist_ok=True)
    
    for case_data in data.get('cases', []):
        case_id = case_data.get('case_id', case_data.get('name', 'unknown'))
        case_folder = cases_dir / case_id
        
        if case_folder.exists() and import_mode == "Ajouter aux cas existants":
            continue
        
        case_folder.mkdir(exist_ok=True)
        
        # Sauvegarder mÃ©tadonnÃ©es
        metadata_file = case_folder / "metadata.json"
        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump(case_data, f, indent=2, ensure_ascii=False)
        
        st.info(f"ğŸ“‹ MÃ©tadonnÃ©es importÃ©es : {case_id}")

def restore_backup(backup_file):
    """Restaure backup complet"""
    
    try:
        with st.spinner("ğŸ”„ Restauration en cours..."):
            # Sauvegarde temporaire
            temp_backup_dir = Path("temp_backup_current")
            if temp_backup_dir.exists():
                shutil.rmtree(temp_backup_dir)
            
            # Extraire backup
            with zipfile.ZipFile(backup_file, 'r') as zipf:
                zipf.extractall("temp_restore")
            
            restore_dir = Path("temp_restore")
            
            # Restaurer chaque composant
            components = {
                "data/ecg_cases": restore_dir / "ecg_cases",
                "data/ecg_sessions": restore_dir / "ecg_sessions", 
                "users": restore_dir / "users"
            }
            
            for target, source in components.items():
                if source.exists():
                    target_path = Path(target)
                    
                    # Backup actuel
                    if target_path.exists():
                        shutil.rmtree(target_path)
                    
                    # Restaurer
                    target_path.parent.mkdir(exist_ok=True)
                    shutil.copytree(source, target_path)
            
            # Nettoyage
            shutil.rmtree(restore_dir)
        
        st.success("âœ… Restauration terminÃ©e !")
        st.info("ğŸ”„ RedÃ©marrez l'application pour voir les changements")
        
    except Exception as e:
        st.error(f"âŒ Erreur restauration : {e}")

def get_file_size(file_path):
    """Retourne taille formatÃ©e du fichier"""
    
    size_bytes = file_path.stat().st_size
    
    if size_bytes < 1024:
        return f"{size_bytes} B"
    elif size_bytes < 1024**2:
        return f"{size_bytes/1024:.1f} KB"
    elif size_bytes < 1024**3:
        return f"{size_bytes/(1024**2):.1f} MB"
    else:
        return f"{size_bytes/(1024**3):.1f} GB"

def show_backup_info(backup_path):
    """Affiche informations dÃ©taillÃ©es du backup"""
    
    try:
        with zipfile.ZipFile(backup_path, 'r') as zipf:
            files = zipf.namelist()
            
            st.info(f"""
            **ğŸ“¦ Informations Backup**
            - **Fichiers** : {len(files)}
            - **Taille** : {get_file_size(Path(backup_path))}
            - **Cas ECG** : {len([f for f in files if 'ecg_cases' in f])}
            - **Sessions** : {len([f for f in files if 'ecg_sessions' in f])}
            """)
            
    except Exception as e:
        st.error(f"âŒ Erreur lecture backup : {e}")

def handle_restore_confirmation(backup_path, idx):
    """GÃ¨re confirmation restauration"""
    
    st.warning(f"âš ï¸ Restaurer {Path(backup_path).name} ?")
    
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("âœ… Confirmer", key=f"conf_restore_{idx}"):
            restore_backup(backup_path)
            del st.session_state[f"confirm_restore_{idx}"]
            st.rerun()
    
    with col2:
        if st.button("âŒ Annuler", key=f"canc_restore_{idx}"):
            del st.session_state[f"confirm_restore_{idx}"]
            st.rerun()

def handle_delete_confirmation(backup_path, idx):
    """GÃ¨re confirmation suppression"""
    
    st.warning(f"ğŸ—‘ï¸ Supprimer {Path(backup_path).name} ?")
    
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("ğŸ—‘ï¸ Supprimer", key=f"conf_delete_{idx}"):
            Path(backup_path).unlink()
            st.success("âœ… Backup supprimÃ©")
            del st.session_state[f"confirm_delete_{idx}"]
            st.rerun()
    
    with col2:
        if st.button("âŒ Annuler", key=f"canc_delete_{idx}"):
            del st.session_state[f"confirm_delete_{idx}"]
            st.rerun()

if __name__ == "__main__":
    display_backup_system()
